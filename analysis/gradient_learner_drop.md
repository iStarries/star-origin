# VOC 15-5 step1 梯度学习器实验性能回落说明

## 现象
- 日志显示 step1 使用了所谓“梯度学习器”方案后，mIoU 从基准的 74.45 降到 73.99（下降约 0.46）。

## 代码侧的关键信息
1. 训练入口 `train_voc.py` 的命令行参数仅包含基础开关（任务、批大小、是否蒸馏等），并未注册 `--use_consistency_filter`、`--use_separate_old_update` 或伪梯度缩放等选项。因此在当前代码中，这些参数即便从脚本传入也会被忽略，训练流程不会执行梯度学习器或一致性过滤/分离式更新的逻辑。
2. 当前训练脚本 `scripts/voc/overlapped/train_voc_15-5.sh` 把上述开关和缩放参数串到命令里，同时还将 batch size/epoch 配置成 `--bs 8 --epochs 80`。这些参数可以导致与之前基准（如 batch size 24、60 epoch）不同的优化路径，即使模型逻辑不变，最终指标也可能有波动。

## 性能下降的可能原因
- **梯度学习器并未真正生效**：由于 CLI 未注册相关开关，本次运行仍是“无梯度学习器”的原始训练流程，mIoU 变化主要来源于超参数或随机性，而非梯度学习器本身。
- **超参数变化引入波动**：脚本中较小的 batch size（8）和更长的训练轮次（80）会改变优化轨迹；再加上数据顺序和随机增强，容易造成 0.4～0.5 mIoU 的自然方差。

## 建议
1. 如果要验证梯度学习器的真实影响，需先在 `train_voc.py`/`trainer_voc.py` 中显式接线相关选项，再固定与基准一致的超参数（如 batch size、epoch 数、随机种子），减少干扰变量。
2. 在未修改代码的情况下，若仅想复现基准，请将脚本中的 batch size/epoch 调回基准设置，并去掉无效的额外参数，减少因配置差异带来的波动。
